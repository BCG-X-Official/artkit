{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b98ee1-cb0f-4ff2-bb18-79b1cdd1b7d2",
   "metadata": {},
   "source": [
    "# JSON Output Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f214c1ad-9c0a-477a-a498-509660c96982",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "When setting up ARTKIT pipelines, you'll often want to parse multiple values from a model's response. In these cases, prompting the model to return JSON-formatted output is incredibly useful.\n",
    "\n",
    "Many of the best commercial models are able to reliably produce JSONs in a particular format. Some LLM providers can even guarantee a specific output format, by setting invalid token probabilities to 0 when sampling the next token.\n",
    "\n",
    "However, if you are using a weaker model, have a high temperature, or require a complex custom format for your model response (perhaps not even JSON), it can be helpful to validate the output before passing it to the next step in the pipeline. \n",
    "\n",
    "To support JSON formatting, ARTKIT provides the `parse_json_autofix` utility function. Below, we'll show you how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a57a99-e691-4b91-b746-1ae31a7576df",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "We'll start with a simple example that uses a JSON output format to pass model results between pipeline steps. In this case, we'll ask an LLM for the five most populous states, and then multiply their population by two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1671dfea-ef74-4eac-b6fc-1c07762208c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import artkit.api as ak\n",
    "from artkit.model.llm.util import parse_json_autofix\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "gpt_chat = ak.CachedChatModel(\n",
    "    ak.OpenAIChat(\n",
    "        model_id=\"gpt-3.5-turbo\",\n",
    "        seed=0,\n",
    "     ), \n",
    "    database=\"./cache/json_output_validation.db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10468b16-e918-4350-932f-a6e830c233e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th colspan=\"2\" halign=\"left\">get_states</th>\n",
       "      <th colspan=\"2\" halign=\"left\">multiply_population</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>state</th>\n",
       "      <th>population</th>\n",
       "      <th>factor</th>\n",
       "      <th>multiplied_population</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>California</td>\n",
       "      <td>39538223</td>\n",
       "      <td>2</td>\n",
       "      <td>79076446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Texas</td>\n",
       "      <td>29145505</td>\n",
       "      <td>2</td>\n",
       "      <td>58291010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Florida</td>\n",
       "      <td>21538187</td>\n",
       "      <td>2</td>\n",
       "      <td>43076374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>New York</td>\n",
       "      <td>20201249</td>\n",
       "      <td>2</td>\n",
       "      <td>40402498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>13002700</td>\n",
       "      <td>2</td>\n",
       "      <td>26005400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     input    get_states            multiply_population                      \n",
       "         n         state population              factor multiplied_population\n",
       "item                                                                         \n",
       "0        5    California   39538223                   2              79076446\n",
       "1        5         Texas   29145505                   2              58291010\n",
       "2        5       Florida   21538187                   2              43076374\n",
       "3        5      New York   20201249                   2              40402498\n",
       "4        5  Pennsylvania   13002700                   2              26005400"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_prompt = \"\"\"\\\n",
    "Given an input integer 'N', list the 'N' most populous states in the United States.\n",
    "\n",
    "# Output Format\n",
    "[\n",
    "  {{\n",
    "    \"state\": \"<state1>\",\n",
    "    \"population\": <state1 population>,\n",
    "  }},\n",
    "  {{\n",
    "    \"state\": \"<state2>\",\n",
    "    \"populate\": <state2 population>,\n",
    "  }}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "async def get_states(n: int, llm: ak.ChatModel):\n",
    "    for response in await llm.get_response(message=str(n)):\n",
    "        json_response = json.loads(response)\n",
    "        for item in json_response:\n",
    "            # Note that the model response will always be a string, so we need to explicitly\n",
    "            #   cast \"population\" as an into to use in later steps\n",
    "            yield {\"state\": item[\"state\"], \"population\": int(item[\"population\"])}\n",
    "\n",
    "def multiply_population(population: int, factor: int):\n",
    "    return {\"factor\": factor, \"multiplied_population\": population * factor}\n",
    "\n",
    "\n",
    "# Run the steps and print results\n",
    "steps = ak.chain(\n",
    "    ak.step(\"get_states\", get_states, llm=gpt_chat.with_system_prompt(state_prompt)),\n",
    "    ak.step(\"multiply_population\", multiply_population, factor=2)\n",
    ")\n",
    "input = [{\"n\": 5}]\n",
    "result = ak.run(input=input, steps=steps)\n",
    "result.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621d42a4-cae0-498e-9d92-44f15ebe2faa",
   "metadata": {},
   "source": [
    "If the model made small errors in the output format, the above pipeline would fail with a `JSONDecodeError`. We'll handle this by calling `parse_json_autofix` before loading the raw model output as a JSON, which will use an LLM to attempt to fix any errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2ea9445-969c-4057-af08-149f311f409a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:artkit.model.llm.util._json:Attempting to fix malformed JSON:\n",
      "[\n",
      "  {\n",
      "    state: \"California\",\n",
      "    population: 39538223\n",
      "  },\n",
      "  {\n",
      "    state: \"Texas\"\n",
      "    population: 29145505\n",
      "  },\n",
      "  {\n",
      "    \"state\": \"Florida\",\n",
      "    population: \"21538187\"\n",
      "  },\n",
      "  {\n",
      "    state: \"New York\",\n",
      "    \"population\": 20201249\n",
      "  },\n",
      "  {\n",
      "    state: \"Pennsylvania\",\n",
      "    population: 12820878\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th colspan=\"2\" halign=\"left\">get_states</th>\n",
       "      <th colspan=\"2\" halign=\"left\">multiply_population</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>state</th>\n",
       "      <th>population</th>\n",
       "      <th>factor</th>\n",
       "      <th>multiplied_population</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>California</td>\n",
       "      <td>39538223</td>\n",
       "      <td>2</td>\n",
       "      <td>79076446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Texas</td>\n",
       "      <td>29145505</td>\n",
       "      <td>2</td>\n",
       "      <td>58291010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Florida</td>\n",
       "      <td>21538187</td>\n",
       "      <td>2</td>\n",
       "      <td>43076374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>New York</td>\n",
       "      <td>20201249</td>\n",
       "      <td>2</td>\n",
       "      <td>40402498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>12820878</td>\n",
       "      <td>2</td>\n",
       "      <td>25641756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     input    get_states            multiply_population                      \n",
       "         n         state population              factor multiplied_population\n",
       "item                                                                         \n",
       "0        5    California   39538223                   2              79076446\n",
       "1        5         Texas   29145505                   2              58291010\n",
       "2        5       Florida   21538187                   2              43076374\n",
       "3        5      New York   20201249                   2              40402498\n",
       "4        5  Pennsylvania   12820878                   2              25641756"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_state_prompt = state_prompt + \"\"\"\\\n",
    "\\nYou must introduce a few small errors in the output format, such as adding or removing commas, colons, quotation marks.\n",
    "\"\"\"\n",
    "\n",
    "async def get_and_validate_states(n: int, llm: ak.ChatModel):\n",
    "    for response in await llm.with_system_prompt(error_state_prompt).get_response(message=str(n)):\n",
    "        # Instead of calling json.loads directly, we'll pass the result to parse_json_autofix\n",
    "        parsed_response = await parse_json_autofix(json=response, model=llm)\n",
    "        for item in parsed_response:\n",
    "            yield {\"state\": item[\"state\"], \"population\": item[\"population\"]}\n",
    "\n",
    "\n",
    "# Run the steps and print results\n",
    "error_steps = ak.chain(\n",
    "    ak.step(\"get_states\", get_and_validate_states, llm=gpt_chat),\n",
    "    ak.step(\"multiply_population\", multiply_population, factor=2)\n",
    ")\n",
    "result = ak.run(input=input, steps=error_steps)\n",
    "result.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e58211-7001-4ade-8fc5-c72172c5486e",
   "metadata": {},
   "source": [
    "ARTKIT logs a warning that the original JSON output was malformed â€” however, we can see that after running `parse_json_autofix`, our final results are the same as in the initial run. Under the hood, `parse_json_autofix` sends a query to the LLM with the malformed json together with the error message, and asks the LLM to fix the error message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935c4381",
   "metadata": {},
   "source": [
    "## Concluding remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67b0cfb",
   "metadata": {},
   "source": [
    "In order to enforce that an LLM's output follows a particular format, the most reliable method is to normalize token probabilities after deterministically setting all invalid tokens' probabilities to 0. However, this approach is infeasible for most projects, since they often do not have access to the model. For the special case of JSON and the latest OpenAI models, you can use the `response_format` [parameter](https://platform.openai.com/docs/guides/text-generation/json-mode).\n",
    "\n",
    "This notebook uses an approach that works more generally:\n",
    "\n",
    "- apply a parser to the output\n",
    "- show any eventual parsing errors to the LLM\n",
    "- ask the LLM to resolve the error\n",
    "\n",
    "We have shown how to efficiently implement this approach with ARTKIT's `parse_json_autofix`, which can be used to validate and fix JSON-formatted output from any LLM.\n",
    "\n",
    "If you have other ideas on this topic, please consider [contributing](../../contributor_guide/index.rst)! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
